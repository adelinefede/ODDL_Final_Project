import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import cv2
import math
import csv
import os
import zipfile

# Define keypoints
KEYPOINT_DICT = {
    0: 'nose', 1: 'left_eye', 2: 'right_eye', 3: 'left_ear', 4: 'right_ear',
    5: 'left_shoulder', 6: 'right_shoulder', 7: 'left_elbow', 8: 'right_elbow',
    9: 'left_wrist', 10: 'right_wrist', 11: 'left_hip', 12: 'right_hip',
    13: 'left_knee', 14: 'right_knee', 15: 'left_ankle', 16: 'right_ankle'
}

EDGES = {
    ('left_shoulder', 'right_shoulder'): (0, 255, 0),
    ('left_shoulder', 'left_elbow'): (255, 0, 0),
    ('left_elbow', 'left_wrist'): (255, 0, 0),
    ('right_shoulder', 'right_elbow'): (0, 0, 255),
    ('right_elbow', 'right_wrist'): (0, 0, 255),
    ('left_shoulder', 'left_hip'): (255, 0, 0),
    ('right_shoulder', 'right_hip'): (0, 0, 255),
    ('left_hip', 'right_hip'): (0, 255, 0),
    ('left_hip', 'left_knee'): (255, 0, 0),
    ('left_knee', 'left_ankle'): (255, 0, 0),
    ('right_hip', 'right_knee'): (0, 0, 255),
    ('right_knee', 'right_ankle'): (0, 0, 255)
}

def compute_vectors_and_angles(keypoints, width, height, threshold=0.3):
    kp_dict = {}
    for i, kp in enumerate(keypoints):
        y, x, score = kp
        if score > threshold:
            kp_dict[KEYPOINT_DICT[i]] = (int(x * width), int(y * height))
    vectors, angles = {}, {}
    for (p1, p2) in EDGES:
        if p1 in kp_dict and p2 in kp_dict:
            x1, y1 = kp_dict[p1]
            x2, y2 = kp_dict[p2]
            vx, vy = x2 - x1, y2 - y1
            angle = math.degrees(math.atan2(vy, vx))
            vectors[(p1, p2)] = (vx, vy)
            angles[(p1, p2)] = abs(angle)
    return vectors, angles

def extract_posture_from_video(
    video_path,
    output_csv,
    posture_label,
    output_dir="posture_frames",
    model_url="https://tfhub.dev/google/movenet/singlepose/lightning/4"
):
    import os
    os.makedirs(output_dir, exist_ok=True)
    model = hub.load(model_url).signatures['serving_default']
    input_size = 192

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise IOError("Cannot open video")

    edge_keys = list(EDGES.keys())
    vector_cols = [f"{a}_{b}_vx" for a, b in edge_keys] + [f"{a}_{b}_vy" for a, b in edge_keys]
    angle_cols = [f"{a}_{b}_angle" for a, b in edge_keys]
    header = ['frame_filename'] + vector_cols + angle_cols + ['label']

    write_header = not os.path.exists(output_csv)
    with open(output_csv, 'a', newline='') as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(header)

        frame_index = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            h, w, _ = frame.shape
            resized = tf.image.resize_with_pad(np.expand_dims(frame, axis=0), input_size, input_size)
            input_tensor = tf.cast(resized, dtype=tf.int32)
            keypoints = model(input_tensor)['output_0'].numpy()[0, 0, :, :]

            vectors, angles = compute_vectors_and_angles(keypoints, w, h)

            frame_filename = f"{posture_label}_frame_{frame_index:04d}.jpg"
            frame_path = os.path.join(output_dir, frame_filename)
            cv2.imwrite(frame_path, frame)

            row = [frame_filename]
            for edge in edge_keys:
                vx, vy = vectors.get(edge, (0, 0))
                row.extend([vx, vy])
            for edge in edge_keys:
                angle = angles.get(edge, 0)
                row.append(angle)
            row.append(posture_label)

            writer.writerow(row)
            frame_index += 1

        cap.release()
    print(f"Saved {frame_index} and rows to {output_csv} and {output_dir}/")

good_posture_path = "/content/drive/MyDrive/Dataset/Good_Posture.mp4"
bad_posture_path = "/content/drive/MyDrive/Dataset/Bad_Posture.mp4"
extract_posture_from_video(good_posture_path, "posture.csv", posture_label="good")
extract_posture_from_video(bad_posture_path, "posture.csv", posture_label="bad")

def zip_posture_frames(folder_path='posture_frames', output_zip='posture_frames.zip'):
    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                file_path = os.path.join(root, file)
                arcname = os.path.relpath(file_path, folder_path)  # removes folder_path from path
                zipf.write(file_path, arcname)
    print(f"Folder '{folder_path}' compressed to '{output_zip}'")

zip_posture_frames()

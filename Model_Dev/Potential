import tensorflow as tf
import tensorflow_model_optimization as tfmot
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from sklearn.model_selection import train_test_split
import cv2
import numpy as np
import glob
import zipfile

# Unzip data
with zipfile.ZipFile('posture_frames.zip', 'r') as zip_ref:
    zip_ref.extractall('posture_dir')

def load_images_from_folder(folder, image_size=(32, 32)):
    X, y = [], []
    for filename in glob.glob(f"{folder}/*.jpg"):
        label = 0 if "good" in filename.lower() else 1
        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
        if img is not None:
            img = cv2.resize(img, image_size)
            X.append(img)
            y.append(label)
    return np.array(X), np.array(y)

X, y = load_images_from_folder("posture_dir")
X = X / 255.0
X = X.reshape((-1, 32, 32, 1))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Define CNN
def create_model():
    model = Sequential([
        Conv2D(8, (3, 3), activation='relu', input_shape=(32, 32, 1)),
        MaxPooling2D((2, 2)),
        Conv2D(16, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(32, activation='relu'),
        Dense(1, activation='sigmoid')  # binary classification
    ])
    return model

# Pruning setup
pruning_params = {
    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(
        initial_sparsity=0.0,
        final_sparsity=0.5,
        begin_step=0,
        end_step=1000
    )
}

model = create_model()
pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
pruned_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Callback
callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]

# Train
pruned_model.fit(X_train, y_train,
                 epochs=10,
                 validation_data=(X_test, y_test),
                 callbacks=callbacks)

# Strip pruning
model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)

def representative_dataset_gen():
    for i in range(100):
        yield [X_train[i].reshape(1, 32, 32, 1).astype(np.float32)]

converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model = converter.convert()

with open('pruned_quant_model.tflite', 'wb') as f:
    f.write(tflite_model)

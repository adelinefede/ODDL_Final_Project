import tensorflow as tf
import tensorflow_model_optimization as tfmot
from sklearn.model_selection import train_test_split
import numpy as np
import cv2, glob, zipfile, os

# Unzip and load images
with zipfile.ZipFile('/content/drive/MyDrive/Zip/Copy of posture_frames (1).zip', 'r') as zip_ref:
    zip_ref.extractall('posture_dir')

def load_images_from_folder(folder, image_size=(32, 32)):
    X, y = [], []
    for filename in glob.glob(f"{folder}/*.jpg"):
        label = 0 if "good" in filename.lower() else 1
        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
        if img is not None:
            img = cv2.resize(img, image_size)
            X.append(img)
            y.append(label)
    return np.array(X), np.array(y)

X, y = load_images_from_folder("posture_dir")
X = X / 255.0
X = X.reshape((-1, 32, 32, 1))
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)

# Model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(32, 32, 1)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Prune
pruning_params = {
    "pruning_schedule": tfmot.sparsity.keras.PolynomialDecay(
        initial_sparsity=0.5,
        final_sparsity=0.85,
        begin_step=0,
        end_step=1000
    )
}
pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
pruned_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train
callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]
pruned_model.fit(X_train, y_train, batch_size=32, epochs=6, validation_data=(X_val, y_val), callbacks=callbacks)

# Strip pruning wrappers
model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)

# Quantization
def representative_dataset_gen():
    for i in range(100):
        data = X_train[i].reshape(1, 32, 32, 1)
        yield [data.astype(np.float32)]

converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8

tflite_model = converter.convert()

with open("pruned_quantized_posture_model.tflite", "wb") as f:
    f.write(tflite_model)

print(f"Final TFLite model size: {os.path.getsize('pruned_quantized_posture_model.tflite') / 1024:.2f} KB")
